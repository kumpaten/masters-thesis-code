{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumpaten/masters-thesis-code/blob/main/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIstLh-8b26N",
        "outputId": "77278ca8-947f-4ff1-a3fa-52fedd76cd5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eM7IBQo8K1E"
      },
      "outputs": [],
      "source": [
        "!pip install -U openai tiktoken pandas chardet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l3uLtps1PWL"
      },
      "outputs": [],
      "source": [
        "#@title Run GPT-4o on the 10-K (20-F) filings of each company and return sentiment scores for different aspects\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "import openai\n",
        "import tiktoken\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from openai import RateLimitError, APIError, OpenAIError\n",
        "\n",
        "# Make sure Google Drive is mounted in Colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Configuration\n",
        "env_key = userdata.get('API_KEY_OPENAI')\n",
        "client = openai.OpenAI(api_key=env_key)\n",
        "token_model = 'gpt-4o-mini'\n",
        "\n",
        "# Intangible aspects to score\n",
        "INTANGIBLE_ASPECTS = [\n",
        "    \"Leadership Quality\",\n",
        "    \"Corporate Culture\",\n",
        "    \"Customer Satisfaction Sentiment\",\n",
        "    \"Innovation Sentiment\",\n",
        "    \"Intellectual Property Strength\",\n",
        "    \"Brand Strength\",\n",
        "    \"Corporate Governance Quality\"\n",
        "]\n",
        "\n",
        "# Directory containing one subfolder per company, each with cleaned .txt filings\n",
        "BASE_DIR = '/content/drive/MyDrive/10K-20F-Filings-Cleaned'\n",
        "companies = [d for d in os.listdir(BASE_DIR) if os.path.isdir(os.path.join(BASE_DIR, d))]\n",
        "\n",
        "# Prepare DataFrames\n",
        "scores_df = pd.DataFrame(columns=['Company', 'Year'] + INTANGIBLE_ASPECTS)\n",
        "justifications_df = pd.DataFrame(columns=['Company', 'Year', 'Aspect', 'Justification'])\n",
        "\n",
        "# Function to split long text into chunks\n",
        "def chunk_text(text, max_tokens=100000, model=token_model):\n",
        "    enc = tiktoken.encoding_for_model(model)\n",
        "    tokens = enc.encode(text)\n",
        "    return [enc.decode(tokens[i:i + max_tokens])\n",
        "            for i in range(0, len(tokens), max_tokens)]\n",
        "\n",
        "# Function to call GPT for one chunk\n",
        "def analyze_chunk(chunk, aspects, previous_scores=None, model=token_model):\n",
        "    ref = f\"\\nPrevious year scores: {previous_scores}\\n\" if previous_scores else ''\n",
        "    prompt = f\"\"\"\n",
        "You are a financial analyst assessing a company's annual filing.\n",
        "Rate the following intangible aspects from 0 (very negative) to 10 (very positive):\n",
        "{', '.join(aspects)}\n",
        "{ref}\n",
        "Respond strictly with a markdown table:\n",
        "| Aspect | Score (0-10) | Justification (max 2 sentences) |\n",
        "|--------|--------------|---------------------------------|\n",
        "---\n",
        "{chunk}\n",
        "---\n",
        "\"\"\"\n",
        "    for attempt in range(5):\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0\n",
        "            )\n",
        "            return resp.choices[0].message.content\n",
        "        except (RateLimitError, APIError, OpenAIError) as e:\n",
        "            print(f\"Error (attempt {attempt+1}): {e}. Retrying in 60s...\")\n",
        "            time.sleep(60)\n",
        "    raise RuntimeError(\"Failed after multiple retry attempts.\")\n",
        "\n",
        "# Function to parse GPT's markdown table output\n",
        "def parse_results(markdown):\n",
        "    data = {}\n",
        "    for line in markdown.splitlines():\n",
        "        if line.startswith('|') and 'Aspect' not in line and '---' not in line:\n",
        "            cols = [c.strip() for c in line.strip('|').split('|')]\n",
        "            if len(cols) == 3:\n",
        "                aspect, score, just = cols\n",
        "                data[aspect] = (float(score), just)\n",
        "    return data\n",
        "\n",
        "# Main loop processing all companies and years\n",
        "for company in companies:\n",
        "    comp_dir = os.path.join(BASE_DIR, company)\n",
        "    files = sorted([f for f in os.listdir(comp_dir) if f.endswith('.txt')])\n",
        "    previous = None\n",
        "\n",
        "    for fname in files:\n",
        "        year = os.path.splitext(fname)[0].split('_')[-1]\n",
        "        print(f\"Analyzing {company} ({year})...\")\n",
        "        filepath = os.path.join(comp_dir, fname)\n",
        "\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            text = f.read()\n",
        "\n",
        "        chunks = chunk_text(text)\n",
        "        scores_accum = {asp: [] for asp in INTANGIBLE_ASPECTS}\n",
        "        just_accum = {asp: [] for asp in INTANGIBLE_ASPECTS}\n",
        "\n",
        "        for idx, chunk in enumerate(chunks, 1):\n",
        "            print(f\" Chunk {idx}/{len(chunks)}\")\n",
        "            md_output = analyze_chunk(chunk, INTANGIBLE_ASPECTS, previous)\n",
        "            parsed = parse_results(md_output)\n",
        "            for asp, (sc, just) in parsed.items():\n",
        "                scores_accum[asp].append(sc)\n",
        "                just_accum[asp].append(just)\n",
        "            time.sleep(61)\n",
        "\n",
        "        # Aggregate average scores\n",
        "        avg_scores = {asp: round(sum(v)/len(v), 2) for asp, v in scores_accum.items()}\n",
        "        row = {'Company': company, 'Year': year, **avg_scores}\n",
        "        scores_df = pd.concat([scores_df, pd.DataFrame([row])], ignore_index=True)\n",
        "\n",
        "        # Build justifications entries\n",
        "        for asp, justs in just_accum.items():\n",
        "            combined = ' '.join(justs)\n",
        "            sents = combined.split('. ')\n",
        "            summary = '. '.join(sents[:2]) + ('.' if len(sents) > 2 else '')\n",
        "            just_row = {'Company': company, 'Year': year, 'Aspect': asp, 'Justification': summary}\n",
        "            justifications_df = pd.concat([justifications_df, pd.DataFrame([just_row])], ignore_index=True)\n",
        "\n",
        "        previous = avg_scores\n",
        "\n",
        "        # Save interim results to Drive\n",
        "        scores_df.to_csv('/content/drive/MyDrive/intangible_scores.csv', index=False)\n",
        "        justifications_df.to_csv('/content/drive/MyDrive/intangible_justifications.csv', index=False)\n",
        "        print(\"Saved interim results.\")\n",
        "\n",
        "print(\"All done!\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDccn4uzUKxHJd5Zu1pMIQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}