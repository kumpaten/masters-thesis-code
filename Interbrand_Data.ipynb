{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOXlF6QkBFruO3iPerex2Bl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumpaten/masters-thesis-code/blob/main/Interbrand_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install BeautifulSoup\n",
        "!pip install beautifulsoup4"
      ],
      "metadata": {
        "id": "oHm5i4DYuiyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import json\n",
        "import html\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the filename of your text file containing the HTML content. This assumes that you copy pasted the html content from the website\n",
        "# https://interbrand.com/best-global-brands/apple/ and its element div.m06__chart into a txt file for further processing.\n",
        "# Adjust the file path if necessary.\n",
        "file_path = \"/content/drive/MyDrive/Interbrand_HTML_content.txt\"\n",
        "\n",
        "# Read the HTML content from the file\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "div_tag = soup.find(\"div\", class_=\"m06__chart\")\n",
        "if div_tag is None:\n",
        "    raise ValueError(\"No <div> with class 'm06__chart' found in the file.\")\n",
        "\n",
        "# Extract and unescape the JSON string from the 'data-brands' attribute\n",
        "data_brands_str = div_tag.get(\"data-brands\")\n",
        "data_brands_unescaped = html.unescape(data_brands_str)\n",
        "\n",
        "# Convert the unescaped JSON string to a Python dictionary\n",
        "data_dict = json.loads(data_brands_unescaped)\n",
        "\n",
        "# Define the companies to filter\n",
        "companies_to_filter = [\n",
        "    \"Apple\", \"Microsoft\", \"Facebook\", \"Google\", \"Oracle\",\n",
        "    \"Cisco\", \"Salesforce\", \"SAP\", \"Accenture\", \"IBM\"\n",
        "]\n",
        "\n",
        "# Define the year range filter (inclusive)\n",
        "start_year = 2008\n",
        "end_year = 2021\n",
        "\n",
        "# Prepare a list to store the filtered records\n",
        "records = []\n",
        "\n",
        "# Loop through each company in the data\n",
        "for company, info in data_dict.items():\n",
        "    # Only process companies from our filter list\n",
        "    if company not in companies_to_filter:\n",
        "        continue\n",
        "\n",
        "    years = info.get(\"study_years\", [])\n",
        "    values = info.get(\"brand_values\", [])\n",
        "\n",
        "    # Loop over the paired years and values\n",
        "    for year, value in zip(years, values):\n",
        "        # Only keep the records for years between 2008 and 2021\n",
        "        if start_year <= year <= end_year:\n",
        "            # Convert \"null\" strings to Python None\n",
        "            if isinstance(value, str) and value.lower() == \"null\":\n",
        "                value = None\n",
        "            records.append({\n",
        "                \"Company\": company,\n",
        "                \"Year\": year,\n",
        "                \"Interbrand_Value\": value\n",
        "            })\n",
        "\n",
        "# Create a DataFrame from the records\n",
        "df = pd.DataFrame(records)\n",
        "print(df)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "output_path = '/content/drive/My Drive/Interbrand_data_filtered.csv'\n",
        "df.to_csv(output_path, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7ykUj62lRgN",
        "outputId": "d10e68f3-7b55-4c80-be44-1eb28ce3146b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "       Company  Year  Interbrand_Value\n",
            "0    Accenture  2008            7948.0\n",
            "1    Accenture  2009            7710.0\n",
            "2    Accenture  2010            7481.0\n",
            "3    Accenture  2011            8005.0\n",
            "4    Accenture  2012            8745.0\n",
            "..         ...   ...               ...\n",
            "135        SAP  2017           22635.0\n",
            "136        SAP  2018           22885.0\n",
            "137        SAP  2019           25092.0\n",
            "138        SAP  2020           28011.0\n",
            "139        SAP  2021           30090.0\n",
            "\n",
            "[140 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "until here was the code for the web scraper, now it is the data manipulation that was done directly on the CSV file"
      ],
      "metadata": {
        "id": "_9_ipvAJ6qK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the path to your filtered CSV file on Google Drive.\n",
        "csv_path = '/content/drive/My Drive/Interbrand_data_filtered.csv'\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# -------------------------------\n",
        "# For Oracle, add the known 2023 value first.\n",
        "# According to the source data, Oracle's brand value for 2023 is 34622.\n",
        "# This extra row will serve as an anchor to interpolate the missing 2020 and 2021 values.\n",
        "oracle_extra = pd.DataFrame({\n",
        "    'Company': ['Oracle'],\n",
        "    'Year': [2023],\n",
        "    'Interbrand_Value': [34622]\n",
        "})\n",
        "df = pd.concat([df, oracle_extra], ignore_index=True)\n",
        "\n",
        "# Now, isolate Oracle's data and sort by Year.\n",
        "mask_oracle = df['Company'] == 'Oracle'\n",
        "df_oracle = df[mask_oracle].sort_values('Year')\n",
        "\n",
        "print(\"Oracle data BEFORE interpolation:\")\n",
        "print(df_oracle)\n",
        "\n",
        "# Perform linear interpolation on Oracle's Value column.\n",
        "# limit_direction='both' ensures that missing values at either end (if any) are also filled.\n",
        "df_oracle['Interbrand_Value'] = df_oracle['Interbrand_Value'].interpolate(method='linear', limit_direction='both')\n",
        "\n",
        "print(\"\\nOracle data AFTER interpolation:\")\n",
        "print(df_oracle)\n",
        "\n",
        "# Replace the Oracle rows in the main DataFrame with the interpolated values.\n",
        "# (Sorting again by Year ensures correct assignment.)\n",
        "df.loc[mask_oracle, 'Interbrand_Value'] = df_oracle.sort_values('Year')['Interbrand_Value']\n",
        "\n",
        "# Since your dataset should only span 2008 to 2021, remove the extra 2023 row.\n",
        "df = df[~((df['Company'] == 'Oracle') & (df['Year'] == 2023))]\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file on your Google Drive.\n",
        "output_path = '/content/drive/My Drive/Interbrand_data_filtered_oracle.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "print(\"\\nUpdated data saved to:\", output_path)"
      ],
      "metadata": {
        "id": "bfPTpNfPtP5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55e7d90-54da-492f-92a9-4ff08aa0ae1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oracle data BEFORE interpolation:\n",
            "    Company  Year  Interbrand_Value\n",
            "98   Oracle  2008           13831.0\n",
            "99   Oracle  2009           13699.0\n",
            "100  Oracle  2010           14881.0\n",
            "101  Oracle  2011           17262.0\n",
            "102  Oracle  2012           22126.0\n",
            "103  Oracle  2013           24088.0\n",
            "104  Oracle  2014           25980.0\n",
            "105  Oracle  2015           27283.0\n",
            "106  Oracle  2016           26552.0\n",
            "107  Oracle  2017           27466.0\n",
            "108  Oracle  2018           26133.0\n",
            "109  Oracle  2019           26288.0\n",
            "110  Oracle  2020               NaN\n",
            "111  Oracle  2021               NaN\n",
            "140  Oracle  2023           34622.0\n",
            "\n",
            "Oracle data AFTER interpolation:\n",
            "    Company  Year  Interbrand_Value\n",
            "98   Oracle  2008           13831.0\n",
            "99   Oracle  2009           13699.0\n",
            "100  Oracle  2010           14881.0\n",
            "101  Oracle  2011           17262.0\n",
            "102  Oracle  2012           22126.0\n",
            "103  Oracle  2013           24088.0\n",
            "104  Oracle  2014           25980.0\n",
            "105  Oracle  2015           27283.0\n",
            "106  Oracle  2016           26552.0\n",
            "107  Oracle  2017           27466.0\n",
            "108  Oracle  2018           26133.0\n",
            "109  Oracle  2019           26288.0\n",
            "110  Oracle  2020           29066.0\n",
            "111  Oracle  2021           31844.0\n",
            "140  Oracle  2023           34622.0\n",
            "\n",
            "Updated data saved to: /content/drive/My Drive/Interbrand_data_filtered_oracle.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the path to your filtered oracle CSV file on Google Drive.\n",
        "# Here we assume the file already contains Oracle’s interpolated values\n",
        "# and earlier imputation for Salesforce (if any).\n",
        "csv_path = '/content/drive/My Drive/Interbrand_data_filtered_oracle.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Convert 'Year' and 'Value' to numeric.\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
        "df['Interbrand_Value'] = pd.to_numeric(df['Interbrand_Value'], errors='coerce')\n",
        "\n",
        "# Ensure the imputation indicator column exists (if not, initialize to 0).\n",
        "if 'is_imputed' not in df.columns:\n",
        "    df['is_imputed'] = 0\n",
        "\n",
        "# List companies that had a delayed debut (i.e., their first observed value is well after 2008)\n",
        "# For these companies, we will set pre-debut years to 0.\n",
        "companies_with_delayed_IPO = ['Facebook', 'Salesforce']\n",
        "\n",
        "for company in companies_with_delayed_IPO:\n",
        "    mask = df['Company'] == company\n",
        "    # Find the first year with an observed (non-NA) value.\n",
        "    debut_year = df.loc[mask & df['Interbrand_Value'].notna(), 'Year'].min()\n",
        "    # For years before the debut year, set the Value to 0.\n",
        "    df.loc[mask & (df['Year'] < debut_year), 'Interbrand_Value'] = 0\n",
        "    # Mark these rows as imputed.\n",
        "    df.loc[mask & (df['Year'] < debut_year), 'is_imputed'] = 1\n",
        "\n",
        "# (For Oracle, we leave the imputation indicator as 0 because the interpolated values are trusted.)\n",
        "\n",
        "\n",
        "# Print a summary for each company to verify\n",
        "for company in companies_with_delayed_IPO:\n",
        "    print(f\"\\n{company} data after adjusting pre-debut values:\")\n",
        "    print(df[df['Company'] == company].sort_values('Year'))\n",
        "\n",
        "# Save the final dataset with consistent imputation to a new CSV file.\n",
        "output_path = '/content/drive/My Drive/Interbrand_data_filtered_complete.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "print(\"\\nFinal complete dataset saved to:\", output_path)\n"
      ],
      "metadata": {
        "id": "8FG2rd7pujXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afdeb9d2-717f-4272-9d9a-3a30f38a845d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Facebook data after adjusting pre-debut values:\n",
            "     Company  Year  Interbrand_Value  is_imputed\n",
            "42  Facebook  2008               0.0           1\n",
            "43  Facebook  2009               0.0           1\n",
            "44  Facebook  2010               0.0           1\n",
            "45  Facebook  2011               0.0           1\n",
            "46  Facebook  2012            5421.0           0\n",
            "47  Facebook  2013            7732.0           0\n",
            "48  Facebook  2014           14349.0           0\n",
            "49  Facebook  2015           22029.0           0\n",
            "50  Facebook  2016           32593.0           0\n",
            "51  Facebook  2017           48188.0           0\n",
            "52  Facebook  2018           45168.0           0\n",
            "53  Facebook  2019           39857.0           0\n",
            "54  Facebook  2020           35178.0           0\n",
            "55  Facebook  2021           36248.0           0\n",
            "\n",
            "Salesforce data after adjusting pre-debut values:\n",
            "        Company  Year  Interbrand_Value  is_imputed\n",
            "112  Salesforce  2008               0.0           1\n",
            "113  Salesforce  2009               0.0           1\n",
            "114  Salesforce  2010               0.0           1\n",
            "115  Salesforce  2011               0.0           1\n",
            "116  Salesforce  2012               0.0           1\n",
            "117  Salesforce  2013               0.0           1\n",
            "118  Salesforce  2014               0.0           1\n",
            "119  Salesforce  2015               0.0           1\n",
            "120  Salesforce  2016               0.0           1\n",
            "121  Salesforce  2017            5224.0           0\n",
            "122  Salesforce  2018            6432.0           0\n",
            "123  Salesforce  2019            8004.0           0\n",
            "124  Salesforce  2020           10755.0           0\n",
            "125  Salesforce  2021           14770.0           0\n",
            "\n",
            "Final complete dataset saved to: /content/drive/My Drive/Interbrand_data_filtered_complete.csv\n"
          ]
        }
      ]
    }
  ]
}