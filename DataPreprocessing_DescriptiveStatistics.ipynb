{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXrm29yerYwV1AskaTjn/a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumpaten/masters-thesis-code/blob/main/DataPreprocessing_DescriptiveStatistics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "C6Dk1Q2gycVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Data Overview & Descriptive Statistics\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# ✅ Load dataset\n",
        "file_path = '/content/drive/MyDrive/Data_to_analyze/Final_Dataset_no_NAs.csv'  # Update path if needed\n",
        "df = pd.read_csv(file_path, delimiter=';')\n",
        "\n",
        "# ✅ Set panel index\n",
        "df['year'] = df['year'].astype(int)\n",
        "df.set_index(['company', 'year'], inplace=True)\n",
        "\n",
        "# ✅ Convert dummy variable\n",
        "df['is_imputed'] = df['is_imputed'].astype('category')\n",
        "\n",
        "# ✅ Identify numeric variables, exclude dummies\n",
        "exclude_vars = ['is_imputed']\n",
        "numeric_df = df.select_dtypes(include=['float64', 'int64']).drop(columns=exclude_vars, errors='ignore')\n",
        "\n",
        "# ✅ Multiply growth rates by 100 to express as %\n",
        "growth_vars = ['delta_ln_S5INFT-1', 'delta_ln_GDPWorld-1']\n",
        "for var in growth_vars:\n",
        "    if var in numeric_df.columns:\n",
        "        numeric_df[var] = numeric_df[var] * 100\n",
        "\n",
        "# ✅ Descriptive stats table\n",
        "desc_stats = numeric_df.describe().T[['mean', 'std', 'min', '25%', '50%', '75%', 'max']]\n",
        "desc_stats.columns = ['Mean', 'Std. Dev.', 'Min', '25%', 'Median', '75%', 'Max']\n",
        "desc_stats = desc_stats.round(2)\n",
        "\n",
        "# ✅ Rename variables to LaTeX/print-friendly labels\n",
        "label_map = {\n",
        "    'brand_value': 'Brand Value (USD m)',\n",
        "    'patent_claims': 'Patent Claims',\n",
        "    'TSR': 'TSR (%)',\n",
        "    'Tobins_Q': 'Tobin’s Q',\n",
        "    'PE': 'P/E Ratio',\n",
        "    'ROA-1': 'ROA (%)',\n",
        "    'ln_totalAssets-1': 'ln(Total Assets)',\n",
        "    'ln_totalSales-1': 'ln(Total Sales)',\n",
        "    'SG&A_Intensity': 'SG&A Intensity (%)',\n",
        "    'financialLeverage-1': 'Financial Leverage',\n",
        "    'delta_ln_S5INFT-1': r'$\\Delta$ ln(S5INFT) (%)',\n",
        "    'delta_ln_GDPWorld-1': r'$\\Delta$ ln(GDP World) (%)',\n",
        "    'R&D_Intensity': 'R&D Intensity (%)',\n",
        "    'employee_smoothed_rating': 'Employee Rating',\n",
        "    'Employee Satisfaction Sentiment': 'Employee Sentiment',\n",
        "    'Customer Satisfaction Sentiment': 'Customer Sentiment',\n",
        "    'Innovation Sentiment': 'Innovation Sentiment',\n",
        "    'Intellectual Property Sentiment': 'IP Sentiment',\n",
        "    'Brand Strength Sentiment': 'Brand Sentiment'\n",
        "}\n",
        "desc_stats.index = [label_map.get(var, var) for var in desc_stats.index]\n",
        "\n",
        "# ✅ Show & export\n",
        "from IPython.display import display\n",
        "display(desc_stats)\n",
        "desc_stats.to_csv(\"descriptive_statistics_with_labels.csv\")"
      ],
      "metadata": {
        "id": "tN9Qt-wh4wth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1.5: Data Overview & Descriptive Statistics\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm  # for the normal pdf\n",
        "import os\n",
        "\n",
        "# ——— LaTeX‐style Matplotlib setup ———\n",
        "plt.rcParams.update({\n",
        "    'text.usetex': False,           # mathtext instead of full TeX\n",
        "    'mathtext.fontset': 'stix',\n",
        "    'font.family': 'serif',\n",
        "    'figure.figsize': (6.0, 4.0),   # adjust to your \\textwidth\n",
        "    'axes.labelsize': 10,\n",
        "    'axes.titlesize': 12,\n",
        "    'xtick.labelsize': 9,\n",
        "    'ytick.labelsize': 9,\n",
        "    'legend.fontsize': 9,\n",
        "    'figure.autolayout': True,\n",
        "})\n",
        "\n",
        "# Make an output folder\n",
        "outdir = \"histograms_for_latex\"\n",
        "os.makedirs(outdir, exist_ok=True)\n",
        "\n",
        "for var in numeric_df.columns:\n",
        "    vals = numeric_df[var].dropna().values\n",
        "    μ, σ = vals.mean(), vals.std()\n",
        "\n",
        "    x = np.linspace(vals.min(), vals.max(), 200)\n",
        "    pdf = norm.pdf(x, loc=μ, scale=σ)\n",
        "\n",
        "    # create figure & axes\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.hist(vals, bins='auto', density=True,\n",
        "            edgecolor='black', alpha=0.6,\n",
        "            label='Empirical')\n",
        "    ax.plot(x, pdf, 'k--', linewidth=1.5,\n",
        "            label=rf'Normal($\\mu={μ:.2f},\\,\\sigma={σ:.2f}$)')\n",
        "\n",
        "    ax.set_xlabel(label_map.get(var, var))\n",
        "    ax.set_ylabel('Density')\n",
        "    ax.set_title(rf'Histogram of {label_map.get(var, var)} (pooled)')\n",
        "    ax.legend(loc='upper right')\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # 1) Display inline\n",
        "    plt.show()\n",
        "\n",
        "    # 2) Save vector graphics\n",
        "    safe_var = var.replace(\" \", \"_\").replace(\"/\", \"\")\n",
        "    pdf_path = os.path.join(outdir, f\"hist_{safe_var}.pdf\")\n",
        "    pgf_path = os.path.join(outdir, f\"hist_{safe_var}.pgf\")\n",
        "\n",
        "    fig.savefig(pdf_path, format='pdf', dpi=300, bbox_inches='tight')\n",
        "\n",
        "    plt.close(fig)\n"
      ],
      "metadata": {
        "id": "4pRFzZc9KXVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Data Overview & Descriptive Statistics within firm\n",
        "\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# ✅ Re-select numeric variables (excluding dummy variables)\n",
        "numeric_df = df.select_dtypes(include=['float64', 'int64']).drop(columns=['is_imputed', 'Pre_IPO'], errors='ignore')\n",
        "\n",
        "# ✅ Compute within-firm skewness and kurtosis\n",
        "within_skew = numeric_df.groupby('company').apply(lambda x: x.skew()).T\n",
        "within_kurt = numeric_df.groupby('company').apply(lambda x: x.kurt()).T\n",
        "\n",
        "# ✅ Mean skewness and kurtosis across firms\n",
        "within_dist_stats = pd.DataFrame({\n",
        "    \"Mean Skewness (Within Firm)\": within_skew.mean(axis=1).round(2),\n",
        "    \"Mean Kurtosis (Within Firm)\": within_kurt.mean(axis=1).round(2)\n",
        "})\n",
        "\n",
        "# ✅ Apply LaTeX-friendly labels\n",
        "within_dist_stats.index = [label_map.get(var, var) for var in within_dist_stats.index]\n",
        "\n",
        "# ✅ Sort and display\n",
        "within_dist_stats = within_dist_stats.sort_values(by=\"Mean Skewness (Within Firm)\", ascending=False)\n",
        "display(within_dist_stats)\n",
        "\n",
        "# ✅ Export\n",
        "within_dist_stats.to_csv(\"within_firm_skew_kurtosis_labeled.csv\")\n"
      ],
      "metadata": {
        "id": "32vYCZd_G9Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Transformation of variables\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "# --- Reload original panel data (or continue from your existing df) ---\n",
        "file_path = '/content/drive/MyDrive/Data_to_analyze/Final_Dataset_no_NAs.csv'\n",
        "df = pd.read_csv(file_path, sep=';')\n",
        "df['year'] = df['year'].astype(int)\n",
        "df.set_index(['company','year'], inplace=True)\n",
        "\n",
        "\n",
        "# --- 1) PCR on sentiment variables ---\n",
        "sent_cols = [\n",
        "    'Employee Satisfaction Sentiment',\n",
        "    'Customer Satisfaction Sentiment',\n",
        "    'Innovation Sentiment',\n",
        "    'Intellectual Property Sentiment',\n",
        "    'Brand Strength Sentiment'\n",
        "]\n",
        "\n",
        "# Extract and standardize\n",
        "sent = df[sent_cols].dropna()\n",
        "scaler = StandardScaler()\n",
        "sent_std = scaler.fit_transform(sent)\n",
        "\n",
        "# Fit PCA and get first component\n",
        "pca = PCA(n_components=1)\n",
        "sent_pc1 = pca.fit_transform(sent_std).ravel()\n",
        "\n",
        "# Create a new column and drop the originals\n",
        "df.loc[sent.index, 'Sentiment_PCR'] = sent_pc1\n",
        "df.drop(columns=sent_cols, inplace=True)\n",
        "\n",
        "# ——— Yeo–Johnson transform for the PCR sentiment index ———\n",
        "pt = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "# Fit & apply to the existing Sentiment_PCR column\n",
        "df['YJ(Sentiment_PCR)'] = pt.fit_transform(df[['Sentiment_PCR']])\n",
        "\n",
        "# (Optional) drop the raw PCR if you no longer need it\n",
        "df.drop(columns=['Sentiment_PCR'], inplace=True)\n",
        "\n",
        "# --- 2) Log-transform P/E, TSR, Tobin’s Q etc. in place ---\n",
        "for col in ['PE','TSR','Tobins_Q', 'financialLeverage-1']:\n",
        "    # replace zeros with NaN to avoid -inf\n",
        "    df[col] = np.log(df[col].replace(0, np.nan))\n",
        "\n",
        "    # After taking logs of PE, TSR, and Tobins_Q\n",
        "df.rename(columns={\n",
        "    'PE': 'ln(PE)',\n",
        "    'TSR': 'ln(TSR)',\n",
        "    'Tobins_Q': 'ln(Tobin’s Q)',\n",
        "    'financialLeverage-1': 'ln(Financial Leverage-1)'\n",
        "}, inplace=True)\n",
        "\n",
        "# --- 3) Save transformed dataset, replacing the old one ---\n",
        "out_path = '/content/drive/MyDrive/Data_to_analyze/Final_Dataset_transformed.csv'\n",
        "df.to_csv(out_path, sep=';')\n",
        "\n",
        "print(f\"Saved transformed panel to {out_path}\")\n"
      ],
      "metadata": {
        "id": "WFL8ib1CBPcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Data Overview & Descriptive Statistics within firm on transformed dataset\n",
        "\n",
        "import pandas as pd\n",
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "# 1) Load the transformed dataset\n",
        "file_path = '/content/drive/MyDrive/Data_to_analyze/Final_Dataset_transformed.csv'\n",
        "df = pd.read_csv(file_path, sep=';')\n",
        "\n",
        "# 2) Re-establish panel index\n",
        "df['year'] = df['year'].astype(int)\n",
        "df.set_index(['company', 'year'], inplace=True)\n",
        "\n",
        "# 3) Select numeric variables (drop any leftover dummies)\n",
        "exclude = ['is_imputed', 'Pre_IPO']\n",
        "numeric_df = df.select_dtypes(include=['float64', 'int64']).drop(columns=exclude, errors='ignore')\n",
        "\n",
        "# 4) Compute within-firm skewness and kurtosis\n",
        "#    pandas .skew() and .kurt() both return Fisher (excess) skew/kurtosis by default\n",
        "within_skew = numeric_df.groupby('company').apply(lambda x: x.skew()).T\n",
        "within_kurt = numeric_df.groupby('company').apply(lambda x: x.kurt()).T\n",
        "\n",
        "\n",
        "# 5) Mean skewness & kurtosis across firms\n",
        "within_dist_stats = pd.DataFrame({\n",
        "    \"Mean Skewness (Within Firm)\": within_skew.mean(axis=1).round(2),\n",
        "    \"Mean Excess Kurtosis (Within Firm)\": within_kurt.mean(axis=1).round(2)\n",
        "})\n",
        "\n",
        "# 6) (Optional) Apply LaTeX-friendly labels if you have a label_map dict\n",
        "# within_dist_stats.index = [label_map.get(var, var) for var in within_dist_stats.index]\n",
        "\n",
        "# ✅ Sort and display\n",
        "within_dist_stats = within_dist_stats.sort_values(by=\"Mean Skewness (Within Firm)\", ascending=False)\n",
        "display(within_dist_stats)\n",
        "\n",
        "# 8) Export to CSV\n",
        "within_dist_stats.to_csv(\"within_firm_skew_kurtosis_transformed.csv\")\n"
      ],
      "metadata": {
        "id": "Ue4wRFQUCops"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}