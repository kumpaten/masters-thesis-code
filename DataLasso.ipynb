{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3j8WhIxnDp90dkrhTkyNz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kumpaten/masters-thesis-code/blob/main/DataLasso.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "flic8yMSKFOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lasso Monolith\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LassoCV, Lasso\n",
        "from sklearn.model_selection import RepeatedKFold, train_test_split # train_test_split for bootstrap robustness\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# --- LaTeX Style Plotting Setup ---\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "# Attempt to use a commonly available serif font, or comment out if Times New Roman is installed/critical\n",
        "# plt.rcParams['font.serif'] = ['DejaVu Serif', 'Bitstream Vera Serif', 'Liberation Serif', 'Times New Roman']\n",
        "plt.rcParams['axes.labelsize'] = 10\n",
        "plt.rcParams['xtick.labelsize'] = 8\n",
        "plt.rcParams['ytick.labelsize'] = 8\n",
        "plt.rcParams['legend.fontsize'] = 8\n",
        "plt.rcParams['figure.titlesize'] = 12\n",
        "plt.rcParams['axes.titlesize'] = 10\n",
        "plt.rcParams['figure.figsize'] = (7, 5) # Slightly wider for some plots\n",
        "plt.rcParams['lines.linewidth'] = 1.5\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "plt.rcParams['savefig.format'] = 'pdf'\n",
        "\n",
        "# --- 1. Load Data ---\n",
        "try:\n",
        "    file_path = '/content/drive/MyDrive/Data_to_analyze/Final_Dataset_transformed.csv' # Ensure this is your preprocessed file\n",
        "    df_original = pd.read_csv(file_path, sep=';')\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR: 'Final_Dataset_transformed.csv' not found. Please upload it or check the path.\")\n",
        "    # dummy dataframe to test lasso\n",
        "    data_size = 140\n",
        "    firms = [f'Comp{i%10}' for i in range(data_size)]\n",
        "    years = [2008 + i//10 for i in range(data_size)][:data_size] # ensure years match data_size\n",
        "    df_original = pd.DataFrame({\n",
        "        'company': firms[:len(years)], 'year': years,\n",
        "        'ln(Tobin’s Q)': np.random.rand(len(years)) * 2 + 0.5,\n",
        "        'ln(PE)': np.random.rand(len(years)) * 30 + 5,\n",
        "        'ln(TSR)': np.random.rand(len(years)) * 0.5 - 0.1,\n",
        "        'brand_value': np.random.rand(len(years)) * 1000,\n",
        "        'patent_claims': np.random.randint(0, 500, size=len(years)),\n",
        "        'employee_rating': np.random.rand(len(years)) * 2 + 3,\n",
        "        'RD_Intensity': np.random.rand(len(years)) * 0.15,\n",
        "        'SGA_Intensity': np.random.rand(len(years)) * 0.25,\n",
        "        'YJ_Sentiment_PCR': np.random.randn(len(years)),\n",
        "        'is_imputed': np.random.choice([0, 1], size=len(years), p=[0.8, 0.2]),\n",
        "        'ln_total_assets_lag1': np.random.rand(len(years)) * 5 + 10,\n",
        "        'ROA_lag1': np.random.rand(len(years)) * 0.2,\n",
        "        'ln_financial_leverage_lag1': np.random.rand(len(years)) * 1 + 0.5,\n",
        "        'delta_ln_S5INFT_lag1': np.random.randn(len(years)) * 0.1,\n",
        "        'delta_ln_GDPWorld_lag1': np.random.randn(len(years)) * 0.02\n",
        "    })\n",
        "    print(\"Using DUMMY DATA for testing.\")\n",
        "\n",
        "\n",
        "df_original['year'] = df_original['year'].astype(int)\n",
        "df_original.set_index(['company', 'year'], inplace=True)\n",
        "df = df_original.copy()\n",
        "\n",
        "# --- 2. Define Variable Groups (ensure these match your DataFrame column names) ---\n",
        "dependent_vars_list = ['ln(Tobin’s Q)', 'ln(PE)', 'ln(TSR)']\n",
        "contemporaneous_intangibles = [\n",
        "    'brand_value', 'patent_claims', 'employee_smoothed_rating',\n",
        "    'R&D_Intensity', 'SG&A_Intensity', 'YJ(Sentiment_PCR)'\n",
        "]\n",
        "# Using only 'ln_total_assets_lag1' as the size control based on previous discussions\n",
        "firm_controls = [\n",
        "    'ln_totalAssets-1', 'ROA-1', 'ln(Financial Leverage-1)'\n",
        "]\n",
        "macro_controls = [\n",
        "    'delta_ln_S5INFT-1', 'delta_ln_GDPWorld-1'\n",
        "]\n",
        "dummy_controls_contemp = [\"is_imputed\"]\n",
        "\n",
        "# Create lagged intangibles and lagged dummy\n",
        "lagged_intangibles = []\n",
        "for col in contemporaneous_intangibles:\n",
        "    lagged_col_name = f'{col}_lag1'\n",
        "    df[lagged_col_name] = df.groupby(level='company')[col].shift(1)\n",
        "    lagged_intangibles.append(lagged_col_name)\n",
        "df['is_imputed_lag1'] = df.groupby(level='company')['is_imputed'].shift(1)\n",
        "dummy_controls_lagged = [\"is_imputed_lag1\"]\n",
        "\n",
        "# --- 3. Data Preparation Function for Lasso ---\n",
        "def prepare_data_for_lasso(dataf, dep_var_name, predictor_vars_list):\n",
        "    \"\"\"Demeans and standardizes data for Lasso, handling NaNs.\"\"\"\n",
        "    cols_to_use = [dep_var_name] + predictor_vars_list\n",
        "\n",
        "    # Check for missing columns before proceeding\n",
        "    missing_cols_in_df = [col for col in cols_to_use if col not in dataf.columns]\n",
        "    if missing_cols_in_df:\n",
        "        print(f\"ERROR in prepare_data_for_lasso: Columns {missing_cols_in_df} not found in dataframe.\")\n",
        "        return None, None\n",
        "\n",
        "    panel_data = dataf[cols_to_use].copy()\n",
        "\n",
        "    # Demeaning (Within-Transformation)\n",
        "    # Group by firm (level 0 of MultiIndex) and transform\n",
        "    demeaned_data = panel_data.groupby(level='company').transform(lambda x: x - x.mean())\n",
        "\n",
        "    # Separate Y and X after demeaning\n",
        "    y_demeaned = demeaned_data[dep_var_name]\n",
        "    X_demeaned = demeaned_data[predictor_vars_list]\n",
        "\n",
        "    # Drop NaNs that arose from demeaning or original NaNs for this specific model\n",
        "    combined_for_dropna = pd.concat([y_demeaned, X_demeaned], axis=1).dropna()\n",
        "    if combined_for_dropna.empty:\n",
        "        print(f\"Warning: Dataframe empty after demeaning and dropna for DV: {dep_var_name} with predictors: {predictor_vars_list}\")\n",
        "        return None, None\n",
        "\n",
        "    y_final = combined_for_dropna[dep_var_name]\n",
        "    X_final_demeaned = combined_for_dropna[predictor_vars_list]\n",
        "\n",
        "    # Standardization of Predictors (X)\n",
        "    # Fit scaler only on non-NaN values from the *original* X columns before demeaning for this specific set of predictors\n",
        "    # to avoid data leakage from y or from other firms' demeaning process.\n",
        "    # However, for Lasso with demeaned data, standardizing the already demeaned X_final_demeaned is standard.\n",
        "    if not X_final_demeaned.empty:\n",
        "        scaler = StandardScaler()\n",
        "        X_final_standardized = scaler.fit_transform(X_final_demeaned)\n",
        "        X_final_standardized_df = pd.DataFrame(X_final_standardized, columns=X_final_demeaned.columns, index=X_final_demeaned.index)\n",
        "        return y_final, X_final_standardized_df\n",
        "    else:\n",
        "        print(f\"Warning: X_final_demeaned is empty for DV: {dep_var_name}. Cannot standardize.\")\n",
        "        return None, None\n",
        "\n",
        "# --- 4. Lasso CV and Path Plotting Function ---\n",
        "def run_lasso_cv_and_plot_paths(y, X, model_name_display, dep_var_name, scenario_label, n_alphas=100, eps=1e-3):\n",
        "    \"\"\"Runs LassoCV, prints results, and plots coefficient paths.\"\"\"\n",
        "    if y is None or X is None or X.empty or y.empty:\n",
        "        print(f\"Skipping {model_name_display} for {dep_var_name} due to insufficient data.\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"\\n--- Fitting Lasso for: {model_name_display} (DV: {dep_var_name}) ---\")\n",
        "\n",
        "    # Using RepeatedKFold for more stable lambda selection\n",
        "    cv_method = RepeatedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
        "\n",
        "    lasso_cv = LassoCV(alphas=None, cv=cv_method, random_state=42, n_alphas=n_alphas, eps=eps, max_iter=10000, tol=1e-3)\n",
        "    try:\n",
        "        lasso_cv.fit(X, y)\n",
        "    except Exception as e:\n",
        "        print(f\"  ERROR fitting LassoCV for {model_name_display}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    optimal_alpha = lasso_cv.alpha_\n",
        "    print(f\"  Optimal alpha (lambda_min): {optimal_alpha:.6f}\")\n",
        "\n",
        "    # Refit with optimal alpha on the full (prepared) data\n",
        "    final_lasso = Lasso(alpha=optimal_alpha, random_state=42, max_iter=10000, tol=1e-3)\n",
        "    final_lasso.fit(X, y)\n",
        "\n",
        "    coefficients = pd.Series(final_lasso.coef_, index=X.columns)\n",
        "    selected_features = coefficients[coefficients != 0]\n",
        "    print(\"  Selected Features and Coefficients:\")\n",
        "    if not selected_features.empty:\n",
        "        print(selected_features)\n",
        "    else:\n",
        "        print(\"  No features selected.\")\n",
        "\n",
        "    # Plot coefficient paths for Model C\n",
        "    if \"Model C\" in model_name_display: # Only plot paths for full models\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        alphas_lasso, coefs_lasso, _ = lasso_cv.path(X, y, alphas=None, n_alphas=n_alphas, eps=eps, tol=1e-3) # Get paths\n",
        "\n",
        "        # Correctly handle coefs_lasso dimensions\n",
        "        if coefs_lasso.ndim == 1: # If only one feature or one alpha path element\n",
        "             coefs_lasso = coefs_lasso[:, np.newaxis].T # Reshape for consistency\n",
        "\n",
        "        for i in range(coefs_lasso.shape[0]): # Iterate over features\n",
        "             plt.plot(np.log10(alphas_lasso), coefs_lasso[i,:], label=X.columns[i] if coefs_lasso.shape[0] < 15 else None)\n",
        "\n",
        "        plt.axvline(np.log10(optimal_alpha), linestyle='--', color='k', label=f'Optimal $\\lambda$ (log10={np.log10(optimal_alpha):.2f})')\n",
        "        plt.xlabel(r'$\\log_{10}(\\lambda)$')\n",
        "        plt.ylabel('Coefficients')\n",
        "        clean_dep_var = dep_var_name.replace(\"(\", \"\").replace(\")\", \"\").replace(\"’\", \"\").replace(\" \", \"_\")\n",
        "        clean_model_name = model_name_display.replace(\" \",\"_\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"+\",\"plus\")\n",
        "        plt.title(f'Lasso Coefficient Paths: {clean_dep_var}\\n{scenario_label} - {clean_model_name}')\n",
        "        if coefs_lasso.shape[0] < 15 : # Add legend only if not too many features\n",
        "            plt.legend(loc='upper right', bbox_to_anchor=(1.25, 1))\n",
        "        plt.tight_layout(rect=[0, 0, 0.85, 1]) # Adjust layout to make space for legend\n",
        "\n",
        "        plot_filename = f\"lasso_paths_{clean_dep_var}_{scenario_label}_{clean_model_name}.pdf\"\n",
        "        plt.savefig(plot_filename)\n",
        "        plt.show()\n",
        "        print(f\"  Saved Lasso Paths plot to: {plot_filename}\")\n",
        "\n",
        "    return final_lasso, optimal_alpha\n",
        "\n",
        "# --- 5. Bootstrap Lasso Function ---\n",
        "def bootstrap_lasso_feature_selection(y, X, n_bootstrap=100, alpha_cv=5, n_alphas=100, eps=1e-3):\n",
        "    \"\"\"Performs bootstrap Lasso for feature selection stability.\"\"\"\n",
        "    if y is None or X is None or X.empty or y.empty:\n",
        "        print(\"Skipping bootstrap due to insufficient data.\")\n",
        "        return None, None\n",
        "\n",
        "    n_features = X.shape[1]\n",
        "    selected_features_freq = np.zeros(n_features)\n",
        "    avg_coeffs = np.zeros(n_features)\n",
        "\n",
        "    print(f\"\\n--- Running Bootstrap Lasso ({n_bootstrap} replications) ---\")\n",
        "\n",
        "    for i in range(n_bootstrap):\n",
        "        if (i + 1) % (n_bootstrap // 10) == 0:\n",
        "            print(f\"  Bootstrap iteration: {i+1}/{n_bootstrap}\")\n",
        "\n",
        "        # Sample firms with replacement (block bootstrap)\n",
        "        # This requires original multi-index to know which firms to sample\n",
        "        unique_firms = X.index.get_level_values('company').unique()\n",
        "        bootstrap_firms = np.random.choice(unique_firms, size=len(unique_firms), replace=True)\n",
        "\n",
        "        bootstrap_indices = []\n",
        "        for firm in bootstrap_firms:\n",
        "            firm_indices = X.index[X.index.get_level_values('company') == firm]\n",
        "            bootstrap_indices.extend(firm_indices)\n",
        "\n",
        "        X_boot = X.loc[bootstrap_indices]\n",
        "        y_boot = y.loc[bootstrap_indices]\n",
        "\n",
        "        if X_boot.empty or y_boot.empty or len(X_boot) < 10 : # Basic check\n",
        "             print(f\"    Skipping bootstrap iter {i+1} due to empty/small data after resampling.\")\n",
        "             continue\n",
        "\n",
        "        # LassoCV on bootstrap sample\n",
        "        cv_method_boot = RepeatedKFold(n_splits=alpha_cv, n_repeats=1, random_state=i) # Less repeats for speed\n",
        "        lasso_cv_boot = LassoCV(alphas=None, cv=cv_method_boot, random_state=i, n_alphas=n_alphas, eps=eps, max_iter=5000, tol=1e-3) # Fewer max_iter\n",
        "        try:\n",
        "            lasso_cv_boot.fit(X_boot, y_boot)\n",
        "            final_lasso_boot = Lasso(alpha=lasso_cv_boot.alpha_, random_state=i, max_iter=5000, tol=1e-3)\n",
        "            final_lasso_boot.fit(X_boot, y_boot)\n",
        "\n",
        "            selected_mask = final_lasso_boot.coef_ != 0\n",
        "            selected_features_freq += selected_mask\n",
        "            avg_coeffs += final_lasso_boot.coef_\n",
        "        except Exception as e:\n",
        "            print(f\"    Error in bootstrap iteration {i+1}: {e}\")\n",
        "            continue\n",
        "\n",
        "    selection_frequency = selected_features_freq / n_bootstrap\n",
        "    avg_coeffs_on_selected_overall = avg_coeffs / n_bootstrap # This is average over ALL bootstraps, even if coeff was zero\n",
        "\n",
        "    results = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'selection_frequency': selection_frequency,\n",
        "        'average_coefficient': avg_coeffs_on_selected_overall\n",
        "    })\n",
        "    # Calculate average coefficient only for times it was selected (more meaningful)\n",
        "    avg_coeffs_when_selected = np.zeros(n_features)\n",
        "    for j in range(n_features):\n",
        "        # This requires storing all bootstrap coefficients, which is memory intensive.\n",
        "        # For simplicity here, we'll stick to the average over all bootstraps.\n",
        "        # A more advanced version would store all coef_ paths.\n",
        "        pass\n",
        "\n",
        "    print(\"\\n--- Bootstrap Lasso Results ---\")\n",
        "    print(results.sort_values(by='selection_frequency', ascending=False))\n",
        "    return results\n",
        "\n",
        "# --- 6. Define Model Specifications for Lasso (analogous to OLS) ---\n",
        "lasso_scenarios = {}\n",
        "\n",
        "# Scenario 1 (Lasso): Contemporaneous Effects\n",
        "s1_model_a_preds = contemporaneous_intangibles + dummy_controls_contemp\n",
        "s1_model_b_preds = s1_model_a_preds + firm_controls\n",
        "s1_model_c_preds = s1_model_b_preds + macro_controls\n",
        "lasso_scenarios[\"Scenario1_Contemp\"] = {\n",
        "    \"A\": {\"label\": \"Lasso Model A (Intangibles Only)\", \"predictors\": s1_model_a_preds, \"intangible_type\": \"Contemporaneous\"},\n",
        "    \"B\": {\"label\": \"Lasso Model B (+ Firm-Level Controls)\", \"predictors\": s1_model_b_preds, \"intangible_type\": \"Contemporaneous\"},\n",
        "    \"C\": {\"label\": \"Lasso Model C (Full Controls)\", \"predictors\": s1_model_c_preds, \"intangible_type\": \"Contemporaneous\"}\n",
        "}\n",
        "\n",
        "# Scenario 2 (Lasso): Lagged Effects\n",
        "s2_model_a_preds = lagged_intangibles + dummy_controls_lagged\n",
        "s2_model_b_preds = s2_model_a_preds + firm_controls\n",
        "s2_model_c_preds = s2_model_b_preds + macro_controls\n",
        "lasso_scenarios[\"Scenario2_Lagged\"] = {\n",
        "    \"A\": {\"label\": \"Lasso Model A (Lagged Intangibles Only)\", \"predictors\": s2_model_a_preds, \"intangible_type\": \"Lagged\"},\n",
        "    \"B\": {\"label\": \"Lasso Model B (+ Firm-Level Controls)\", \"predictors\": s2_model_b_preds, \"intangible_type\": \"Lagged\"},\n",
        "    \"C\": {\"label\": \"Lasso Model C (Full Controls)\", \"predictors\": s2_model_c_preds, \"intangible_type\": \"Lagged\"}\n",
        "}\n",
        "\n",
        "# --- 7. Execute Lasso Analysis ---\n",
        "all_lasso_results = {}\n",
        "all_bootstrap_lasso_results = {}\n",
        "\n",
        "for dv in dependent_vars_list:\n",
        "    all_lasso_results[dv] = {}\n",
        "    all_bootstrap_lasso_results[dv] = {}\n",
        "    print(f\"\\n\\n{'='*80}\")\n",
        "    print(f\" LASSO ANALYSIS FOR DEPENDENT VARIABLE: {dv} \".center(80, \"=\"))\n",
        "    print(f\"{'='*80}\")\n",
        "\n",
        "    for scenario_key, models in lasso_scenarios.items():\n",
        "        all_lasso_results[dv][scenario_key] = {}\n",
        "        all_bootstrap_lasso_results[dv][scenario_key] = {}\n",
        "        print(f\"\\n--- {scenario_key.replace('_', ' ')} ---\")\n",
        "\n",
        "        for model_key, spec in models.items():\n",
        "            model_label = spec[\"label\"]\n",
        "            predictors = spec[\"predictors\"]\n",
        "\n",
        "            # Prepare data for this specific model\n",
        "            y_prepared, X_prepared = prepare_data_for_lasso(df, dv, predictors)\n",
        "\n",
        "            if y_prepared is not None and X_prepared is not None and not X_prepared.empty:\n",
        "                fitted_lasso, optimal_lambda = run_lasso_cv_and_plot_paths(y_prepared, X_prepared, model_label, dv, scenario_key)\n",
        "                all_lasso_results[dv][scenario_key][model_label] = {\n",
        "                    \"model\": fitted_lasso,\n",
        "                    \"optimal_lambda\": optimal_lambda,\n",
        "                    \"coefficients\": pd.Series(fitted_lasso.coef_, index=X_prepared.columns) if fitted_lasso else None\n",
        "                }\n",
        "\n",
        "                # Run Bootstrap Lasso for Model C (Full Controls)\n",
        "                if model_key == \"C\":\n",
        "                    bootstrap_results = bootstrap_lasso_feature_selection(y_prepared, X_prepared, n_bootstrap=100) # 100 reps for speed, increase for paper\n",
        "                    all_bootstrap_lasso_results[dv][scenario_key][model_label] = bootstrap_results\n",
        "\n",
        "                    if bootstrap_results is not None:\n",
        "                        # Plot Bootstrap Lasso Selection Frequencies\n",
        "                        plt.figure(figsize=(10, 0.3 * len(bootstrap_results['feature']))) # Dynamic height\n",
        "                        bootstrap_results_sorted = bootstrap_results.sort_values('selection_frequency', ascending=True)\n",
        "                        plt.barh(bootstrap_results_sorted['feature'], bootstrap_results_sorted['selection_frequency'], color='skyblue')\n",
        "                        plt.xlabel(\"Selection Frequency\")\n",
        "                        plt.ylabel(\"Predictor\")\n",
        "                        clean_dep_var = dv.replace(\"(\", \"\").replace(\")\", \"\").replace(\"’\", \"\").replace(\" \", \"_\")\n",
        "                        clean_model_name = model_label.replace(\" \",\"_\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"+\",\"plus\")\n",
        "                        plt.title(f'Bootstrap Lasso: Feature Selection Frequency\\n{clean_dep_var} ~ {scenario_key} - {clean_model_name}')\n",
        "                        plt.axvline(0.8, color='red', linestyle='--', label='80% Threshold') # Your >80% threshold\n",
        "                        plt.legend()\n",
        "                        plt.tight_layout()\n",
        "                        plot_filename_boot = f\"bootstrap_lasso_freq_{clean_dep_var}_{scenario_key}_{clean_model_name}.pdf\"\n",
        "                        plt.savefig(plot_filename_boot)\n",
        "                        plt.show()\n",
        "                        print(f\"  Saved Bootstrap Lasso Frequency plot to: {plot_filename_boot}\")\n",
        "            else:\n",
        "                print(f\"Skipping Lasso for {model_label} (DV: {dv}) due to data preparation issues.\")\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*30 + \" END OF LASSO ANALYSIS \" + \"=\"*30)"
      ],
      "metadata": {
        "id": "ye3Z8Bgc5hSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Sgh7q1on5g_R"
      }
    }
  ]
}